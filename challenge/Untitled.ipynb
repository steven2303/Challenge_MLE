{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de709d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Union, List\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "class DelayModel:\n",
    "    def __init__(\n",
    "        self\n",
    "    ):\n",
    "        self._model = None\n",
    "        self._model_path = \"models/delay_model.joblib\" \n",
    "        self._columns_path = \"models/columns.joblib\"\n",
    "        self.features_cols = [\n",
    "            \"OPERA_Latin American Wings\", \n",
    "            \"MES_7\",\n",
    "            \"MES_10\",\n",
    "            \"OPERA_Grupo LATAM\",\n",
    "            \"MES_12\",\n",
    "            \"TIPOVUELO_I\",\n",
    "            \"MES_4\",\n",
    "            \"MES_11\",\n",
    "            \"OPERA_Sky Airline\",\n",
    "            \"OPERA_Copa Air\"\n",
    "        ]\n",
    "        self._opera_categories = None\n",
    "        self._tipo_vuelo_categories = None\n",
    "        self._mes_categories = None\n",
    "\n",
    "    def _get_min_diff(self, data: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate time difference in minutes between Fecha-O and Fecha-I\"\"\"\n",
    "        fecha_o = pd.to_datetime(data['Fecha-O'])\n",
    "        fecha_i = pd.to_datetime(data['Fecha-I'])\n",
    "        min_diff = ((fecha_o - fecha_i).dt.total_seconds())/60\n",
    "        return min_diff\n",
    "\n",
    "    def _save_categories(self) -> None:\n",
    "        \"\"\"Save the dummy categories to disk\"\"\"\n",
    "        categories = {\n",
    "            'opera': self._opera_categories,\n",
    "            'tipo_vuelo': self._tipo_vuelo_categories,\n",
    "            'mes': self._mes_categories\n",
    "        }\n",
    "        Path(self._columns_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        joblib.dump(categories, self._columns_path)\n",
    "\n",
    "    def _load_categories(self) -> None:\n",
    "        \"\"\"Load the dummy categories from disk\"\"\"        \n",
    "        categories = joblib.load(self._columns_path)\n",
    "        self._opera_categories = categories['opera']\n",
    "        self._tipo_vuelo_categories = categories['tipo_vuelo']\n",
    "        self._mes_categories = categories['mes']\n",
    "\n",
    "    def _adjust_dummy_columns(self, dummies: pd.DataFrame, prefix: str, expected_categories: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Adjust dummy columns to match training data columns\"\"\"\n",
    "        expected_columns = [f\"{prefix}{cat}\" for cat in expected_categories]\n",
    "        \n",
    "        # Add missing columns\n",
    "        for col in expected_columns:\n",
    "            if col not in dummies.columns:\n",
    "                dummies[col] = 0\n",
    "                \n",
    "        # Remove extra columns\n",
    "        extra_columns = [col for col in dummies.columns if col not in expected_columns]\n",
    "        dummies.drop(columns=extra_columns, inplace=True, errors='ignore')\n",
    "        \n",
    "        return dummies\n",
    "\n",
    "    def preprocess(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        target_column: str = None\n",
    "    ) -> Union[Tuple[pd.DataFrame, pd.DataFrame], pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare raw data for training or predict.\n",
    "        Args:\n",
    "            data (pd.DataFrame): raw data.\n",
    "            target_column (str, optional): if set, the target is returned.\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame]: features and target.\n",
    "            or\n",
    "            pd.DataFrame: features.\n",
    "        \"\"\"\n",
    "        # Calculate delay\n",
    "        data['min_diff'] = self._get_min_diff(data)\n",
    "        data['delay'] = np.where(data['min_diff'] > 15, 1, 0)\n",
    "\n",
    "        # If in training mode (when target_column is provided), save categories\n",
    "        is_training = target_column is not None\n",
    "\n",
    "        if is_training:\n",
    "            self._opera_categories = data['OPERA'].unique()\n",
    "            self._tipo_vuelo_categories = data['TIPOVUELO'].unique()\n",
    "            self._mes_categories = data['MES'].unique()\n",
    "            self._save_categories()\n",
    "        else:\n",
    "            self._load_categories()\n",
    "            for col, expected_categories in [\n",
    "                ('OPERA', self._opera_categories),\n",
    "                ('TIPOVUELO', self._tipo_vuelo_categories),\n",
    "                ('MES', self._mes_categories)\n",
    "            ]:\n",
    "                valores_entrada = set(data[col].unique())\n",
    "                valores_esperados = set(expected_categories)\n",
    "                valores_incorrectos = valores_entrada - valores_esperados\n",
    "                if valores_incorrectos:\n",
    "                    raise ValueError(\n",
    "                    f\"Unexpected values in the column {col}: {valores_incorrectos}\"\n",
    "                )\n",
    "        \n",
    "        # Get dummy variables for each categorical column and combine them\n",
    "        opera_dummies = pd.get_dummies(data['OPERA'], prefix='OPERA')\n",
    "        tipovuelo_dummies = pd.get_dummies(data['TIPOVUELO'], prefix='TIPOVUELO')\n",
    "        mes_dummies = pd.get_dummies(data['MES'], prefix='MES')\n",
    "\n",
    "        opera_dummies = self._adjust_dummy_columns(opera_dummies, 'OPERA_', self._opera_categories)\n",
    "        tipovuelo_dummies = self._adjust_dummy_columns(tipovuelo_dummies, 'TIPOVUELO_', self._tipo_vuelo_categories)\n",
    "        mes_dummies = self._adjust_dummy_columns(mes_dummies, 'MES_', self._mes_categories)\n",
    "\n",
    "        features = pd.concat([opera_dummies, tipovuelo_dummies, mes_dummies], axis=1)\n",
    "\n",
    "        # Select only the specified features\n",
    "        features = features[self.features_cols]\n",
    "        #features = features.reindex(columns=self.features_cols, fill_value=0)\n",
    "        \n",
    "        if is_training:\n",
    "            target = pd.DataFrame()\n",
    "            target['delay'] = data['delay']\n",
    "            return features, target\n",
    "        else:\n",
    "            return features\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        features: pd.DataFrame,\n",
    "        target: pd.DataFrame\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Fit model with preprocessed data.\n",
    "        Args:\n",
    "            features (pd.DataFrame): preprocessed data.\n",
    "            target (pd.DataFrame): target.\n",
    "        \"\"\"\n",
    "        # Convert target DataFrame to array for LogisticRegression\n",
    "        target_values = target.values.ravel()\n",
    "\n",
    "        # Calculate class weights\n",
    "        n_y0 = np.sum(target_values == 0)\n",
    "        n_y1 = np.sum(target_values == 1)\n",
    "        class_weight = {0: 1, 1: n_y0/n_y1}\n",
    "\n",
    "        # Initialize and train the model\n",
    "        self._model = LogisticRegression(\n",
    "            random_state=1,\n",
    "            class_weight=class_weight,\n",
    "            max_iter=1000\n",
    "        )\n",
    "        \n",
    "        self._model.fit(features, target_values)\n",
    "        self.save_model(self._model_path)\n",
    "\n",
    "    def save_model(\n",
    "        self,\n",
    "        filepath: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Save the trained model to disk.\n",
    "        Args:\n",
    "            filepath (str): Path where the model will be saved\n",
    "        \"\"\"\n",
    "        # Create directory if it doesn't exist\n",
    "        Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(self._model, filepath)\n",
    "\n",
    "    def load_model(\n",
    "        self, \n",
    "        filepath: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Load a trained model from disk.\n",
    "        Args:\n",
    "            filepath (str): Path to the saved model\n",
    "        \"\"\"            \n",
    "        self._model = joblib.load(filepath)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        features: pd.DataFrame\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Predict delays for new flights.\n",
    "        Args:\n",
    "            features (pd.DataFrame): preprocessed data.\n",
    "        Returns:\n",
    "            List[int]: predicted targets.\n",
    "        \"\"\"\n",
    "        if self._model is None:\n",
    "            self.load_model(self._model_path)\n",
    "        \n",
    "        predictions = self._model.predict(features)\n",
    "        return predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "815c17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TestModel(unittest.TestCase):    \n",
    "    FEATURES_COLS = [\n",
    "        \"OPERA_Latin American Wings\", \n",
    "        \"MES_7\",\n",
    "        \"MES_10\",\n",
    "        \"OPERA_Grupo LATAM\",\n",
    "        \"MES_12\",\n",
    "        \"TIPOVUELO_I\",\n",
    "        \"MES_4\",\n",
    "        \"MES_11\",\n",
    "        \"OPERA_Sky Airline\",\n",
    "        \"OPERA_Copa Air\"\n",
    "    ]\n",
    "\n",
    "    TARGET_COL = [\n",
    "        \"delay\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    def setUp(self) -> None:\n",
    "        super().setUp()\n",
    "        self.model = DelayModel()\n",
    "        self.data = pd.read_csv(filepath_or_buffer=\"../data/data.csv\",low_memory=False) ## \n",
    "        #self.model.fit(features=features, target=target)  ## \n",
    "        \n",
    "\n",
    "    def test_model_preprocess_for_training(\n",
    "        self\n",
    "    ):\n",
    "        features, target = self.model.preprocess(\n",
    "            data=self.data,\n",
    "            target_column=\"delay\"\n",
    "        )\n",
    "\n",
    "        assert isinstance(features, pd.DataFrame)\n",
    "        assert features.shape[1] == len(self.FEATURES_COLS)\n",
    "        assert set(features.columns) == set(self.FEATURES_COLS)\n",
    "\n",
    "        assert isinstance(target, pd.DataFrame)\n",
    "        assert target.shape[1] == len(self.TARGET_COL)\n",
    "        assert set(target.columns) == set(self.TARGET_COL)\n",
    "\n",
    "\n",
    "    def test_model_preprocess_for_serving(\n",
    "        self\n",
    "    ):\n",
    "        features = self.model.preprocess(\n",
    "            data=self.data\n",
    "        )\n",
    "\n",
    "        assert isinstance(features, pd.DataFrame)\n",
    "        assert features.shape[1] == len(self.FEATURES_COLS)\n",
    "        assert set(features.columns) == set(self.FEATURES_COLS)\n",
    "\n",
    "\n",
    "    def test_model_fit(\n",
    "        self\n",
    "    ):\n",
    "        features, target = self.model.preprocess(\n",
    "            data=self.data,\n",
    "            target_column=\"delay\"\n",
    "        )\n",
    "\n",
    "        _, features_validation, _, target_validation = train_test_split(features, target, test_size = 0.33, random_state = 42)\n",
    "\n",
    "        self.model.fit(\n",
    "            features=features,\n",
    "            target=target\n",
    "        )\n",
    "\n",
    "        predicted_target = self.model._model.predict(\n",
    "            features_validation\n",
    "        )\n",
    "\n",
    "        report = classification_report(target_validation, predicted_target, output_dict=True)\n",
    "        \n",
    "        assert report[\"0\"][\"recall\"] < 0.60\n",
    "        assert report[\"0\"][\"f1-score\"] < 0.70\n",
    "        assert report[\"1\"][\"recall\"] > 0.60\n",
    "        assert report[\"1\"][\"f1-score\"] > 0.30\n",
    "\n",
    "\n",
    "    def test_model_predict(\n",
    "        self\n",
    "    ):\n",
    "        features = self.model.preprocess(\n",
    "            data=self.data\n",
    "        )\n",
    "\n",
    "        predicted_targets = self.model.predict(\n",
    "            features=features\n",
    "        )\n",
    "        print(predicted_targets)\n",
    "        assert isinstance(predicted_targets, list)\n",
    "        assert len(predicted_targets) == features.shape[0]\n",
    "        assert all(isinstance(predicted_target, int) for predicted_target in predicted_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e224bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b896c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98f6eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.test_model_preprocess_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3ed28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.test_model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e18e05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.test_model_preprocess_for_serving()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9765152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3a8802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "if not a:\n",
    "    print(2)\n",
    "else:\n",
    "    print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de3ddca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_training_categories(categories_path):\n",
    "        \"\"\"Load valid categories from saved training data\"\"\"\n",
    "        categories = joblib.load(categories_path)\n",
    "        #valid_airliness = categories['valid_airliness']\n",
    "        return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d847d7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid_airlines': {'Aerolineas Argentinas',\n",
       "  'Aeromexico',\n",
       "  'Air Canada',\n",
       "  'Air France',\n",
       "  'Alitalia',\n",
       "  'American Airlines',\n",
       "  'Austral',\n",
       "  'Avianca',\n",
       "  'British Airways',\n",
       "  'Copa Air',\n",
       "  'Delta Air',\n",
       "  'Gol Trans',\n",
       "  'Grupo LATAM',\n",
       "  'Iberia',\n",
       "  'JetSmart SPA',\n",
       "  'K.L.M.',\n",
       "  'Lacsa',\n",
       "  'Latin American Wings',\n",
       "  'Oceanair Linhas Aereas',\n",
       "  'Plus Ultra Lineas Aereas',\n",
       "  'Qantas Airways',\n",
       "  'Sky Airline',\n",
       "  'United Airlines'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"D:\\GitHub\\Challenge_MLE\\models\\categories.joblib\"\n",
    "load_training_categories(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66d42d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1261cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351e44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
